# SignBridge - AI-Powered Sign Language Translation

ğŸŒŸ **Bridge Every Voice** - Transform speech and text into expressive sign language with AI-powered 3D avatars and contextual visuals.

## Overview

SignBridge is an innovative accessibility application designed to help deaf and hard-of-hearing individuals by converting voice and text inputs into sign language through:

- **3D Avatar Translation**: Real-time sign language display using animated 3D avatars
- **Voice Recognition**: Advanced speech-to-text conversion with quality analysis
- **Contextual Visuals**: AI-generated visual aids for better understanding
- **Accessibility-First Design**: High contrast, responsive interface optimized for accessibility

## Features

### ğŸ¯ Core Functionality

- **Voice Input**: Real-time speech recognition with volume visualization
- **Text Input**: Direct text entry with keyboard shortcuts
- **3D Sign Language Avatar**: Animated avatar demonstrating sign language gestures
- **Visual Context Generation**: AI-powered contextual images and diagrams
- **Real-time Translation**: Instant conversion from speech/text to sign language

### ğŸ› ï¸ Technology Stack

- **Frontend**: React 18 + TypeScript + Vite + TailwindCSS
- **3D Graphics**: Three.js with React Three Fiber
- **AI/ML**: TensorFlow.js integration ready
- **Voice Recognition**: Web Speech API
- **Backend**: Express.js with RESTful APIs
- **UI Components**: Radix UI with custom accessibility enhancements

### â™¿ Accessibility Features

- **High Contrast Design**: Optimized color scheme for visual accessibility
- **Keyboard Navigation**: Full keyboard support throughout the application
- **Font Size Controls**: Adjustable text sizes for better readability
- **Screen Reader Support**: Semantic HTML and ARIA attributes
- **Focus Management**: Clear focus indicators and logical tab order

## Getting Started

### Prerequisites

- Node.js 18+
- npm or yarn package manager

### Installation

```bash
# Clone the repository
git clone [repository-url]
cd signbridge

# Install dependencies
npm install

# Start development server
npm run dev
```

The application will be available at `http://localhost:8080`

### Build for Production

```bash
# Build the application
npm run build

# Start production server
npm start
```

## API Endpoints

### Translation API

- `POST /api/translate` - Convert text to sign language gestures
- `GET /api/translation-status` - Get translation service status

### Voice Processing API

- `POST /api/voice/process` - Process audio input and transcribe
- `GET /api/voice/settings` - Get voice recognition settings
- `POST /api/voice/settings` - Update voice recognition settings

### Development API

- `GET /api/ping` - Health check endpoint
- `GET /api/placeholder/:width/:height` - Placeholder images for development

## Project Structure

```
signbridge/
â”œâ”€â”€ client/                 # React frontend
â”‚   â”œâ”€â”€ components/        # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ ui/           # Shadcn/ui component library
â”‚   â”‚   â”œâ”€â”€ VoiceInput.tsx        # Voice/text input component
â”‚   â”‚   â”œâ”€â”€ Avatar3D.tsx          # 3D avatar display
â”‚   â”‚   â”œâ”€â”€ ContextualVisuals.tsx # Visual context generator
â”‚   â”‚   â””â”€â”€ AccessibilityHeader.tsx # App header with a11y controls
â”‚   â”œâ”€â”€ pages/            # Application pages
â”‚   â”‚   â””â”€â”€ Index.tsx     # Main application page
â”‚   â””â”€â”€ global.css        # Global styles and theme
â”œâ”€â”€ server/               # Express backend
â”‚   â”œâ”€â”€ routes/          # API route handlers
â”‚   â”‚   â”œâ”€â”€ translation.ts        # Sign language translation
â”‚   â”‚   â””â”€â”€ voice-processing.ts   # Voice recognition processing
â”‚   â””â”€â”€ index.ts         # Server setup and middleware
â”œâ”€â”€ shared/              # Shared types and utilities
â”‚   â””â”€â”€ api.ts          # API interface definitions
â””â”€â”€ public/             # Static assets
```

## Future Integrations

### Planned Technology Integrations

- **Google Agent Development Kit**: Enhanced conversational AI
- **TensorFlow/Keras**: Advanced ML models for gesture recognition
- **OpenCV**: Computer vision for gesture analysis
- **Cloud Translation APIs**: Multi-language support

### Roadmap Features

- [ ] Advanced gesture recognition
- [ ] Multi-language sign language support (ASL, BSL, ISL)
- [ ] User profile and preference saving
- [ ] Video recording and export functionality
- [ ] Real-time collaboration features
- [ ] Mobile application (React Native)
- [ ] Offline mode support

## Contributing

We welcome contributions from the community, especially from deaf and hard-of-hearing developers and users who can provide valuable feedback on accessibility and usability.

### Development Guidelines

1. Follow accessibility best practices
2. Maintain high contrast design standards
3. Test with screen readers and keyboard navigation
4. Include proper ARIA labels and semantic HTML
5. Document any new accessibility features

## Accessibility Statement

SignBridge is committed to providing an inclusive experience for all users. The application follows WCAG 2.1 AA guidelines and includes:

- Keyboard-only navigation support
- Screen reader compatibility
- High contrast color schemes
- Adjustable font sizes
- Clear focus indicators
- Descriptive alt text and labels

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- Built with â¤ï¸ for the deaf and hard-of-hearing community
- Inspired by the need for accessible communication technology
- Special thanks to accessibility advocates and testers

---

**Empowering communication through accessible technology** ğŸŒŸ
